{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Parsing Silk Road Forums HTML files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "import codecs\n",
    "import os\n",
    "from dateutil.parser import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wdir = \"/home/abyun/Downloads/w251_proj/silkroad1-forums/practice/\"\n",
    "\n",
    "#Ensure the current directory is correctly set\n",
    "os.chdir(wdir)\n",
    "#Build a Pandas data frame to hold the new data\n",
    "col_names_topic = [\"Topic\",\"Date\",\"Author\",\"Author_numposts\",\"Author_type\",\"Author_karma\",\"Response_date\",\n",
    "                   \"Responder\",\"Responder_numposts\",\"Responder_type\",\"Responder_karma\"]\n",
    "col_names_profile = [\"User\",\"User_numposts\",\"User_type\",\"User_karma\",\"Date_registered\",\"Last_active\"]\n",
    "df_topic = pd.DataFrame(columns = col_names_topic)\n",
    "df_profile = pd.DataFrame(columns = col_names_profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File index.php?topic=22162.0 has failed\n"
     ]
    }
   ],
   "source": [
    "for i in os.listdir(os.getcwd()): #Loops through all files in the current directory\n",
    "    try:\n",
    "        if i.find(\"profile\") != -1: #forum profile page\n",
    "            soup = BeautifulSoup(open(i,'r').read()) \n",
    "            \n",
    "            user_info = soup.find(\"div\",attrs={\"class\":\"username\"}) \n",
    "            user_block = user_info.find(\"h4\").get_text()\n",
    "            user = user_block.split(\" \")[0]\n",
    "            user_type = user_info.find(\"span\",attrs={\"class\":\"position\"}).get_text()\n",
    "            \n",
    "            more_user_info = soup.find(\"div\",attrs={\"class\":\"windowbg2\"})\n",
    "            more_user_info_table = more_user_info.find(\"div\",attrs={\"class\":\"content\"}) \n",
    "            table_rows = more_user_info_table.find_all(\"dd\")\n",
    "            user_numposts = table_rows[0].get_text()\n",
    "            user_karma = table_rows[1].get_text()\n",
    "            date_registered = parse(table_rows[3].get_text())\n",
    "            last_active = parse(table_rows[5].get_text())           \n",
    "\n",
    "            #Creates a numpy array with the scraped values\n",
    "            new_p = np.array([user,user_numposts,user_type,user_karma,date_registered,last_active])\n",
    "            #Appends array to data frame\n",
    "            df_profile = df_profile.append(pd.DataFrame(new_p, index=col_names_profile).transpose())            \n",
    "\n",
    "        elif i.find(\"topic\") != -1: #forum topic page\n",
    "            soup = BeautifulSoup(open(i,'r').read()) \n",
    "\n",
    "            forum_board = soup.find(\"div\",attrs={\"id\":\"forumposts\"})\n",
    "\n",
    "            #individual posts\n",
    "            forum_post = forum_board.find_all(\"div\",attrs={\"class\":[\"windowbg\",\"windowbg2\"]})\n",
    "\n",
    "            #first post\n",
    "            main_post = forum_post[0]\n",
    "            post_info = main_post.find(\"div\",attrs={\"class\":\"postarea\"})\n",
    "            topic_tag = str(post_info.find(\"a\"))\n",
    "            topic = topic_tag[topic_tag.index(\">\")+1:topic_tag[1:len(topic_tag)].index(\"<\")+1]\n",
    "            date_text_tag = str(post_info.find(\"div\",attrs={\"class\":\"smalltext\"}))\n",
    "            date = date_text_tag[date_text_tag.find(\"/strong>\")+9:date_text_tag.find(\"</div\")-2]\n",
    "            try: \n",
    "                date = parse(date)\n",
    "            except:\n",
    "                date = parse(\"0:00\")\n",
    "            poster_info = main_post.find(\"div\",attrs={\"class\":\"poster\"})\n",
    "            author_tag = str(poster_info.find(\"a\"))\n",
    "            author_text = author_tag.split(\" \")[-1]\n",
    "            author = author_text[author_text.index(\">\")+1:author_text.index(\"<\")]\n",
    "            author_numposts_tag = str(poster_info.find(\"li\",{\"class\":\"postcount\"}))\n",
    "            author_numposts_text = author_numposts_tag.split(\" \")[-1]\n",
    "            author_numposts = author_numposts_text[0:author_numposts_text.index(\"<\")] \n",
    "            author_type_tag = str(poster_info.find(\"li\",{\"class\":\"postgroup\"}))\n",
    "            author_type_text = author_type_tag.split(\" \")[-1]\n",
    "            author_type = author_type_text[author_type_text.index(\">\")+1:author_type_text.index(\"<\")] \n",
    "            author_karma_tag = str(poster_info.find(\"li\",{\"class\":\"karma\"}))\n",
    "            author_karma_text = author_karma_tag.split(\" \")[-1]\n",
    "            author_karma = author_karma_text[0:author_karma_text.index(\"<\")]\n",
    "\n",
    "            #response post(s)\n",
    "            if len(forum_post) > 1:\n",
    "                for j in range(1, len(forum_post)):\n",
    "                    response = forum_post[j]\n",
    "                    responder_info = response.find(\"div\",attrs={\"class\":\"poster\"})\n",
    "                    response_date_text_tag = str(responder_info.find(\"div\",attrs={\"class\":\"smalltext\"}))\n",
    "                    response_date = response_date_text_tag[response_date_text_tag.find(\"/strong>\")+9:response_date_text_tag.find(\"</div\")-2]\n",
    "                    try: \n",
    "                        response_date = parse(response_date)\n",
    "                    except:\n",
    "                        response_date = parse(\"0:00\")\n",
    "                    responder_tag = str(responder_info.find(\"a\"))\n",
    "                    responder_text = responder_tag.split(\" \")[-1]\n",
    "                    responder = responder_text[responder_text.index(\">\")+1:responder_text.index(\"<\")]                \n",
    "                    responder_numposts_tag = str(responder_info.find(\"li\",{\"class\":\"postcount\"}))\n",
    "                    responder_numposts_text = responder_numposts_tag.split(\" \")[-1]\n",
    "                    responder_numposts = responder_numposts_text[0:responder_numposts_text.index(\"<\")] \n",
    "                    \n",
    "                    responder_type_tag = str(responder_info.find(\"li\",{\"class\":\"postgroup\"}))\n",
    "                    responder_type_text = responder_type_tag.split(\" \")[-1]\n",
    "                    responder_type = responder_type_text[responder_type_text.index(\">\")+1:responder_type_text.index(\"<\")] \n",
    "                    responder_karma_tag = str(responder_info.find(\"li\",{\"class\":\"karma\"}))\n",
    "                    responder_karma_text = responder_karma_tag.split(\" \")[-1]\n",
    "                    responder_karma = responder_karma_text[0:responder_karma_text.index(\"<\")]                \n",
    "\n",
    "                    #Creates a numpy array with the scraped values\n",
    "                    new_t = np.array([topic, date, author, author_numposts, author_type, author_karma, response_date,\n",
    "                                   responder, responder_numposts, responder_type, responder_karma])\n",
    "                    #Appends array to data frame\n",
    "                    df_topic = df_topic.append(pd.DataFrame(new_t, index=col_names_topic).transpose())\n",
    "\n",
    "            else:\n",
    "                response_date = \"0:00\"\n",
    "                responder = \"\"\n",
    "                responder_numposts = \"\"\n",
    "                responder_type = \"\"\n",
    "                responder_karma = \"\"\n",
    "\n",
    "                #Creates a numpy array with the scraped values\n",
    "                new_t = np.array([topic, date, author, author_numposts, author_type, author_karma, response_date,\n",
    "                               responder, responder_numposts, responder_type, responder_karma])\n",
    "                #Appends array to data frame\n",
    "                df_topic = df_topic.append(pd.DataFrame(new_t, index=col_names_topic).transpose())\n",
    "                \n",
    "\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    except:\n",
    "        print \"File \" + i + \" has failed\"\n",
    "\n",
    "os.chdir(wdir) #Reset current working directory\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 User       User_numposts User_type User_karma  \\\n",
      "0  Rogersslipperyhand   4 (0.017 per day)    Newbie      +0/-0   \n",
      "0      Psychadelic777   1 (0.004 per day)    Newbie      +0/-0   \n",
      "0     RiverCityRansom  19 (0.082 per day)    Newbie      +0/-0   \n",
      "\n",
      "       Date_registered          Last_active  \n",
      "0  2013-03-15 05:37:00  2013-07-21 01:28:00  \n",
      "0  2013-03-15 05:39:00  2013-04-04 02:48:00  \n",
      "0  2013-03-15 05:38:00  2013-04-02 23:41:00  \n"
     ]
    }
   ],
   "source": [
    "print df_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Topic                 Date  \\\n",
      "0  ▌฿ ▌bitcoin fundation memeber www.bitcoratio.c...  2016-03-07 00:00:00   \n",
      "0  ▌฿ ▌bitcoin fundation memeber www.bitcoratio.c...  2016-03-07 00:00:00   \n",
      "0  ▌฿ ▌bitcoin fundation memeber www.bitcoratio.c...  2016-03-07 00:00:00   \n",
      "0     Re: Hardly no Cocaine in The Cocaine on SR yet  2012-05-17 18:11:00   \n",
      "0  ▌฿ ▌bitcoin fundation memeber www.bitcoratio.c...  2016-03-07 00:00:00   \n",
      "0  ▌฿ ▌bitcoin fundation memeber www.bitcoratio.c...  2016-03-07 00:00:00   \n",
      "0  ▌฿ ▌bitcoin fundation memeber www.bitcoratio.c...  2016-03-07 00:00:00   \n",
      "0     Re: Hardly no Cocaine in The Cocaine on SR yet  2012-05-17 18:11:00   \n",
      "0  ▌฿ ▌bitcoin fundation memeber www.bitcoratio.c...  2016-03-07 00:00:00   \n",
      "0  ▌฿ ▌bitcoin fundation memeber www.bitcoratio.c...  2016-03-07 00:00:00   \n",
      "0  ▌฿ ▌bitcoin fundation memeber www.bitcoratio.c...  2016-03-07 00:00:00   \n",
      "0  ▌฿ ▌bitcoin fundation memeber www.bitcoratio.c...  2016-03-07 00:00:00   \n",
      "0  ▌฿ ▌bitcoin fundation memeber www.bitcoratio.c...  2016-03-07 00:00:00   \n",
      "0  ▌฿ ▌bitcoin fundation memeber www.bitcoratio.c...  2016-03-07 00:00:00   \n",
      "0  ▌฿ ▌bitcoin fundation memeber www.bitcoratio.c...  2016-03-07 00:00:00   \n",
      "0  ▌฿ ▌bitcoin fundation memeber www.bitcoratio.c...  2016-03-07 00:00:00   \n",
      "0  ▌฿ ▌bitcoin fundation memeber www.bitcoratio.c...  2016-03-07 00:00:00   \n",
      "0  ▌฿ ▌bitcoin fundation memeber www.bitcoratio.c...  2016-03-07 00:00:00   \n",
      "0  ▌฿ ▌bitcoin fundation memeber www.bitcoratio.c...  2016-03-07 00:00:00   \n",
      "0  ▌฿ ▌bitcoin fundation memeber www.bitcoratio.c...  2016-03-07 00:00:00   \n",
      "0                                        need advice  2012-05-07 15:35:00   \n",
      "0                                        need advice  2012-05-07 15:35:00   \n",
      "0                                        need advice  2012-05-07 15:35:00   \n",
      "0                                        need advice  2012-05-07 15:35:00   \n",
      "0                                        need advice  2012-05-07 15:35:00   \n",
      "0                                        need advice  2012-05-07 15:35:00   \n",
      "0                                        need advice  2012-05-07 15:35:00   \n",
      "0                                        need advice  2012-05-07 15:35:00   \n",
      "0  ▌฿ ▌bitcoin fundation memeber www.bitcoratio.c...  2016-03-07 00:00:00   \n",
      "0         Hardly no Cocaine in The Cocaine on SR yet  2012-05-07 15:39:00   \n",
      "0         Hardly no Cocaine in The Cocaine on SR yet  2012-05-07 15:39:00   \n",
      "0         Hardly no Cocaine in The Cocaine on SR yet  2012-05-07 15:39:00   \n",
      "0         Hardly no Cocaine in The Cocaine on SR yet  2012-05-07 15:39:00   \n",
      "0         Hardly no Cocaine in The Cocaine on SR yet  2012-05-07 15:39:00   \n",
      "0         Hardly no Cocaine in The Cocaine on SR yet  2012-05-07 15:39:00   \n",
      "0         Hardly no Cocaine in The Cocaine on SR yet  2012-05-07 15:39:00   \n",
      "0         Hardly no Cocaine in The Cocaine on SR yet  2012-05-07 15:39:00   \n",
      "0         Hardly no Cocaine in The Cocaine on SR yet  2012-05-07 15:39:00   \n",
      "0         Hardly no Cocaine in The Cocaine on SR yet  2012-05-07 15:39:00   \n",
      "0         Hardly no Cocaine in The Cocaine on SR yet  2012-05-07 15:39:00   \n",
      "0         Hardly no Cocaine in The Cocaine on SR yet  2012-05-07 15:39:00   \n",
      "0  ▌฿ ▌bitcoin fundation memeber www.bitcoratio.c...  2016-03-07 00:00:00   \n",
      "0  ▌฿ ▌bitcoin fundation memeber www.bitcoratio.c...  2016-03-07 00:00:00   \n",
      "0  ▌฿ ▌bitcoin fundation memeber www.bitcoratio.c...  2016-03-07 00:00:00   \n",
      "0  ▌฿ ▌bitcoin fundation memeber www.bitcoratio.c...  2016-03-07 00:00:00   \n",
      "0  ▌฿ ▌bitcoin fundation memeber www.bitcoratio.c...  2016-03-07 00:00:00   \n",
      "0  ▌฿ ▌bitcoin fundation memeber www.bitcoratio.c...  2016-03-07 00:00:00   \n",
      "0  ▌฿ ▌bitcoin fundation memeber www.bitcoratio.c...  2016-03-07 00:00:00   \n",
      "0  ▌฿ ▌bitcoin fundation memeber www.bitcoratio.c...  2016-03-07 00:00:00   \n",
      "\n",
      "             Author Author_numposts Author_type Author_karma  \\\n",
      "0    htrshreswhuy54              66                    +0/-0   \n",
      "0      hnuyyttrdtrd               2      Newbie        +0/-0   \n",
      "0      hnuyyttrdtrd               5      Newbie        +0/-0   \n",
      "0         dankology             553                  +27/-30   \n",
      "0      hnuyyttrdtrd               2      Newbie        +0/-0   \n",
      "0    htrshreswhuy54              55                    +0/-0   \n",
      "0    htrshreswhuy54              65                    +0/-0   \n",
      "0         dankology             553                  +27/-30   \n",
      "0      hnuyyttrdtrd              10      Newbie        +0/-0   \n",
      "0      hnuyyttrdtrd              10      Newbie        +0/-0   \n",
      "0    htrshreswhuy54              63                    +0/-0   \n",
      "0      hnuyyttrdtrd              10      Newbie        +0/-0   \n",
      "0    htrshreswhuy54              63                    +0/-0   \n",
      "0      hnuyyttrdtrd               5      Newbie        +0/-0   \n",
      "0    htrshreswhuy54              65                    +0/-0   \n",
      "0      hnuyyttrdtrd              13      Newbie        +0/-0   \n",
      "0      hnuyyttrdtrd               5      Newbie        +0/-0   \n",
      "0    htrshreswhuy54              63                    +0/-0   \n",
      "0      hnuyyttrdtrd              11      Newbie        +0/-0   \n",
      "0    htrshreswhuy54              63                    +0/-0   \n",
      "0            newguy               6      Newbie        +0/-0   \n",
      "0            newguy               6      Newbie        +0/-0   \n",
      "0            newguy               6      Newbie        +0/-0   \n",
      "0            newguy               6      Newbie        +0/-0   \n",
      "0            newguy               6      Newbie        +0/-0   \n",
      "0            newguy               6      Newbie        +0/-0   \n",
      "0            newguy               6      Newbie        +0/-0   \n",
      "0            newguy               6      Newbie        +0/-0   \n",
      "0    htrshreswhuy54              58                    +0/-0   \n",
      "0  eternalcausation              43      Newbie        +1/-2   \n",
      "0  eternalcausation              43      Newbie        +1/-2   \n",
      "0  eternalcausation              43      Newbie        +1/-2   \n",
      "0  eternalcausation              43      Newbie        +1/-2   \n",
      "0  eternalcausation              43      Newbie        +1/-2   \n",
      "0  eternalcausation              43      Newbie        +1/-2   \n",
      "0  eternalcausation              43      Newbie        +1/-2   \n",
      "0  eternalcausation              43      Newbie        +1/-2   \n",
      "0  eternalcausation              43      Newbie        +1/-2   \n",
      "0  eternalcausation              43      Newbie        +1/-2   \n",
      "0  eternalcausation              43      Newbie        +1/-2   \n",
      "0  eternalcausation              43      Newbie        +1/-2   \n",
      "0    htrshreswhuy54              58                    +0/-0   \n",
      "0      hnuyyttrdtrd              11      Newbie        +0/-0   \n",
      "0      hnuyyttrdtrd              10      Newbie        +0/-0   \n",
      "0    htrshreswhuy54              63                    +0/-0   \n",
      "0    htrshreswhuy54              54                    +0/-0   \n",
      "0      hnuyyttrdtrd              16      Newbie        +0/-0   \n",
      "0      hnuyyttrdtrd              16      Newbie        +0/-0   \n",
      "0      hnuyyttrdtrd              13      Newbie        +0/-0   \n",
      "\n",
      "         Response_date         Responder Responder_numposts Responder_type  \\\n",
      "0                 0:00                                                       \n",
      "0                 0:00                                                       \n",
      "0                 0:00                                                       \n",
      "0  2016-03-07 00:00:00        technofarm                500                  \n",
      "0                 0:00                                                       \n",
      "0                 0:00                                                       \n",
      "0                 0:00                                                       \n",
      "0  2016-03-07 00:00:00        technofarm                500                  \n",
      "0                 0:00                                                       \n",
      "0                 0:00                                                       \n",
      "0                 0:00                                                       \n",
      "0                 0:00                                                       \n",
      "0                 0:00                                                       \n",
      "0                 0:00                                                       \n",
      "0                 0:00                                                       \n",
      "0                 0:00                                                       \n",
      "0                 0:00                                                       \n",
      "0                 0:00                                                       \n",
      "0                 0:00                                                       \n",
      "0                 0:00                                                       \n",
      "0  2016-03-07 00:00:00              twon                357                  \n",
      "0  2016-03-07 00:00:00            newguy                  6         Newbie   \n",
      "0  2016-03-07 00:00:00       blackend646                873                  \n",
      "0  2016-03-07 00:00:00            newguy                  6         Newbie   \n",
      "0  2016-03-07 00:00:00         sniper123               1263                  \n",
      "0  2016-03-07 00:00:00            newguy                  6         Newbie   \n",
      "0  2016-03-07 00:00:00       Marshall123                 41         Newbie   \n",
      "0  2016-03-07 00:00:00            newguy                  6         Newbie   \n",
      "0                 0:00                                                       \n",
      "0  2016-03-07 00:00:00              twon                357                  \n",
      "0  2016-03-07 00:00:00  eternalcausation                 43         Newbie   \n",
      "0  2016-03-07 00:00:00         sniper123               1263                  \n",
      "0  2016-03-07 00:00:00         sniper123               1263                  \n",
      "0  2016-03-07 00:00:00         sniper123               1263                  \n",
      "0  2016-03-07 00:00:00  eternalcausation                 43         Newbie   \n",
      "0  2016-03-07 00:00:00         sniper123               1263                  \n",
      "0  2016-03-07 00:00:00  eternalcausation                 43         Newbie   \n",
      "0  2016-03-07 00:00:00   frank-butcher24                310                  \n",
      "0  2016-03-07 00:00:00  eternalcausation                 43         Newbie   \n",
      "0  2016-03-07 00:00:00        ilovelsd69                717                  \n",
      "0  2016-03-07 00:00:00         ksquizzle                434                  \n",
      "0                 0:00                                                       \n",
      "0                 0:00                                                       \n",
      "0                 0:00                                                       \n",
      "0                 0:00                                                       \n",
      "0                 0:00                                                       \n",
      "0                 0:00                                                       \n",
      "0                 0:00                                                       \n",
      "0                 0:00                                                       \n",
      "\n",
      "  Responder_karma  \n",
      "0                  \n",
      "0                  \n",
      "0                  \n",
      "0         +23/-11  \n",
      "0                  \n",
      "0                  \n",
      "0                  \n",
      "0         +23/-11  \n",
      "0                  \n",
      "0                  \n",
      "0                  \n",
      "0                  \n",
      "0                  \n",
      "0                  \n",
      "0                  \n",
      "0                  \n",
      "0                  \n",
      "0                  \n",
      "0                  \n",
      "0                  \n",
      "0          +13/-6  \n",
      "0           +0/-0  \n",
      "0         +65/-35  \n",
      "0           +0/-0  \n",
      "0         +36/-23  \n",
      "0           +0/-0  \n",
      "0           +1/-3  \n",
      "0           +0/-0  \n",
      "0                  \n",
      "0          +13/-6  \n",
      "0           +1/-2  \n",
      "0         +36/-23  \n",
      "0         +36/-23  \n",
      "0         +36/-23  \n",
      "0           +1/-2  \n",
      "0         +36/-23  \n",
      "0           +1/-2  \n",
      "0          +27/-6  \n",
      "0           +1/-2  \n",
      "0         +31/-13  \n",
      "0         +22/-19  \n",
      "0                  \n",
      "0                  \n",
      "0                  \n",
      "0                  \n",
      "0                  \n",
      "0                  \n",
      "0                  \n",
      "0                  \n"
     ]
    }
   ],
   "source": [
    "print df_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Remove duplicates from \"Feedback\" pages\n",
    "df_profile = df_profile.drop_duplicates(keep=\"first\")\n",
    "#Re-indexes the dataframe\n",
    "df_profile.index = range(df_profile.shape[0])\n",
    "\n",
    "#Remove duplicates from \"Feedback\" pages\n",
    "df_topic = df_topic.drop_duplicates(keep=\"first\")\n",
    "#Re-indexes the dataframe\n",
    "df_topic.index = range(df_topic.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_profile.to_csv(\"data_output/df_profile.csv\")\n",
    "df_topic.to_csv(\"data_output/df_topic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Topic                 Date  \\\n",
      "0   ▌฿ ▌bitcoin fundation memeber www.bitcoratio.c...  2016-03-07 00:00:00   \n",
      "1   ▌฿ ▌bitcoin fundation memeber www.bitcoratio.c...  2016-03-07 00:00:00   \n",
      "2   ▌฿ ▌bitcoin fundation memeber www.bitcoratio.c...  2016-03-07 00:00:00   \n",
      "3      Re: Hardly no Cocaine in The Cocaine on SR yet  2012-05-17 18:11:00   \n",
      "4   ▌฿ ▌bitcoin fundation memeber www.bitcoratio.c...  2016-03-07 00:00:00   \n",
      "5   ▌฿ ▌bitcoin fundation memeber www.bitcoratio.c...  2016-03-07 00:00:00   \n",
      "6   ▌฿ ▌bitcoin fundation memeber www.bitcoratio.c...  2016-03-07 00:00:00   \n",
      "7   ▌฿ ▌bitcoin fundation memeber www.bitcoratio.c...  2016-03-07 00:00:00   \n",
      "8   ▌฿ ▌bitcoin fundation memeber www.bitcoratio.c...  2016-03-07 00:00:00   \n",
      "9   ▌฿ ▌bitcoin fundation memeber www.bitcoratio.c...  2016-03-07 00:00:00   \n",
      "10                                        need advice  2012-05-07 15:35:00   \n",
      "11                                        need advice  2012-05-07 15:35:00   \n",
      "12                                        need advice  2012-05-07 15:35:00   \n",
      "13                                        need advice  2012-05-07 15:35:00   \n",
      "14                                        need advice  2012-05-07 15:35:00   \n",
      "15  ▌฿ ▌bitcoin fundation memeber www.bitcoratio.c...  2016-03-07 00:00:00   \n",
      "16         Hardly no Cocaine in The Cocaine on SR yet  2012-05-07 15:39:00   \n",
      "17         Hardly no Cocaine in The Cocaine on SR yet  2012-05-07 15:39:00   \n",
      "18         Hardly no Cocaine in The Cocaine on SR yet  2012-05-07 15:39:00   \n",
      "19         Hardly no Cocaine in The Cocaine on SR yet  2012-05-07 15:39:00   \n",
      "20         Hardly no Cocaine in The Cocaine on SR yet  2012-05-07 15:39:00   \n",
      "21         Hardly no Cocaine in The Cocaine on SR yet  2012-05-07 15:39:00   \n",
      "22  ▌฿ ▌bitcoin fundation memeber www.bitcoratio.c...  2016-03-07 00:00:00   \n",
      "23  ▌฿ ▌bitcoin fundation memeber www.bitcoratio.c...  2016-03-07 00:00:00   \n",
      "\n",
      "              Author Author_numposts Author_type Author_karma  \\\n",
      "0     htrshreswhuy54              66                    +0/-0   \n",
      "1       hnuyyttrdtrd               2      Newbie        +0/-0   \n",
      "2       hnuyyttrdtrd               5      Newbie        +0/-0   \n",
      "3          dankology             553                  +27/-30   \n",
      "4     htrshreswhuy54              55                    +0/-0   \n",
      "5     htrshreswhuy54              65                    +0/-0   \n",
      "6       hnuyyttrdtrd              10      Newbie        +0/-0   \n",
      "7     htrshreswhuy54              63                    +0/-0   \n",
      "8       hnuyyttrdtrd              13      Newbie        +0/-0   \n",
      "9       hnuyyttrdtrd              11      Newbie        +0/-0   \n",
      "10            newguy               6      Newbie        +0/-0   \n",
      "11            newguy               6      Newbie        +0/-0   \n",
      "12            newguy               6      Newbie        +0/-0   \n",
      "13            newguy               6      Newbie        +0/-0   \n",
      "14            newguy               6      Newbie        +0/-0   \n",
      "15    htrshreswhuy54              58                    +0/-0   \n",
      "16  eternalcausation              43      Newbie        +1/-2   \n",
      "17  eternalcausation              43      Newbie        +1/-2   \n",
      "18  eternalcausation              43      Newbie        +1/-2   \n",
      "19  eternalcausation              43      Newbie        +1/-2   \n",
      "20  eternalcausation              43      Newbie        +1/-2   \n",
      "21  eternalcausation              43      Newbie        +1/-2   \n",
      "22    htrshreswhuy54              54                    +0/-0   \n",
      "23      hnuyyttrdtrd              16      Newbie        +0/-0   \n",
      "\n",
      "          Response_date         Responder Responder_numposts Responder_type  \\\n",
      "0                  0:00                                                       \n",
      "1                  0:00                                                       \n",
      "2                  0:00                                                       \n",
      "3   2016-03-07 00:00:00        technofarm                500                  \n",
      "4                  0:00                                                       \n",
      "5                  0:00                                                       \n",
      "6                  0:00                                                       \n",
      "7                  0:00                                                       \n",
      "8                  0:00                                                       \n",
      "9                  0:00                                                       \n",
      "10  2016-03-07 00:00:00              twon                357                  \n",
      "11  2016-03-07 00:00:00            newguy                  6         Newbie   \n",
      "12  2016-03-07 00:00:00       blackend646                873                  \n",
      "13  2016-03-07 00:00:00         sniper123               1263                  \n",
      "14  2016-03-07 00:00:00       Marshall123                 41         Newbie   \n",
      "15                 0:00                                                       \n",
      "16  2016-03-07 00:00:00              twon                357                  \n",
      "17  2016-03-07 00:00:00  eternalcausation                 43         Newbie   \n",
      "18  2016-03-07 00:00:00         sniper123               1263                  \n",
      "19  2016-03-07 00:00:00   frank-butcher24                310                  \n",
      "20  2016-03-07 00:00:00        ilovelsd69                717                  \n",
      "21  2016-03-07 00:00:00         ksquizzle                434                  \n",
      "22                 0:00                                                       \n",
      "23                 0:00                                                       \n",
      "\n",
      "   Responder_karma  \n",
      "0                   \n",
      "1                   \n",
      "2                   \n",
      "3          +23/-11  \n",
      "4                   \n",
      "5                   \n",
      "6                   \n",
      "7                   \n",
      "8                   \n",
      "9                   \n",
      "10          +13/-6  \n",
      "11           +0/-0  \n",
      "12         +65/-35  \n",
      "13         +36/-23  \n",
      "14           +1/-3  \n",
      "15                  \n",
      "16          +13/-6  \n",
      "17           +1/-2  \n",
      "18         +36/-23  \n",
      "19          +27/-6  \n",
      "20         +31/-13  \n",
      "21         +22/-19  \n",
      "22                  \n",
      "23                  \n"
     ]
    }
   ],
   "source": [
    "print df_topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final script to deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "import codecs\n",
    "import os\n",
    "from dateutil.parser import parse\n",
    "\n",
    "#wdir = \"/home/abyun/Downloads/w251_proj/silkroad1-forums/practice/\"\n",
    "wdir = \"/sandisk1/darknetmarket/silkroad1-forums/2013-11-03/\"\n",
    "\n",
    "#Ensure the current directory is correctly set\n",
    "os.chdir(wdir)\n",
    "#Build a Pandas data frame to hold the new data\n",
    "col_names_topic = [\"Topic\",\"Date\",\"Author\",\"Author_numposts\",\"Author_type\",\"Author_karma\",\"Response_date\",\n",
    "                   \"Responder\",\"Responder_numposts\",\"Responder_type\",\"Responder_karma\"]\n",
    "col_names_profile = [\"User\",\"User_numposts\",\"User_type\",\"User_karma\",\"Date_registered\",\"Last_active\"]\n",
    "df_topic = pd.DataFrame(columns = col_names_topic)\n",
    "df_profile = pd.DataFrame(columns = col_names_profile)\n",
    "\n",
    "for i in sorted(os.listdir(os.getcwd())): #Loops through all files in the current directory\n",
    "    try:\n",
    "        if i.find(\"profile\") != -1: #forum profile page\n",
    "            soup = BeautifulSoup(open(i,'r').read()) \n",
    "            \n",
    "            user_info = soup.find(\"div\",attrs={\"class\":\"username\"}) \n",
    "            user_block = user_info.find(\"h4\").get_text()\n",
    "            user = user_block.split(\" \")[0]\n",
    "            user_type = user_info.find(\"span\",attrs={\"class\":\"position\"}).get_text()\n",
    "            \n",
    "            more_user_info = soup.find(\"div\",attrs={\"class\":\"windowbg2\"})\n",
    "            more_user_info_table = more_user_info.find(\"div\",attrs={\"class\":\"content\"}) \n",
    "            table_rows = more_user_info_table.find_all(\"dd\")\n",
    "            user_numposts = table_rows[0].get_text()\n",
    "            user_karma = table_rows[1].get_text()\n",
    "            date_registered = parse(table_rows[3].get_text())\n",
    "            last_active = parse(table_rows[5].get_text())           \n",
    "\n",
    "            #Creates a numpy array with the scraped values\n",
    "            new_p = np.array([user,user_numposts,user_type,user_karma,date_registered,last_active])\n",
    "            #Appends array to data frame\n",
    "            df_profile = df_profile.append(pd.DataFrame(new_p, index=col_names_profile).transpose())            \n",
    "\n",
    "        elif i.find(\"topic\") != -1: #forum topic page\n",
    "            soup = BeautifulSoup(open(i,'r').read()) \n",
    "\n",
    "            forum_board = soup.find(\"div\",attrs={\"id\":\"forumposts\"})\n",
    "\n",
    "            #individual posts\n",
    "            forum_post = forum_board.find_all(\"div\",attrs={\"class\":[\"windowbg\",\"windowbg2\"]})\n",
    "\n",
    "            #first post\n",
    "            main_post = forum_post[0]\n",
    "            post_info = main_post.find(\"div\",attrs={\"class\":\"postarea\"})\n",
    "            topic_tag = str(post_info.find(\"a\"))\n",
    "            topic = topic_tag[topic_tag.index(\">\")+1:topic_tag[1:len(topic_tag)].index(\"<\")+1]\n",
    "            date_text_tag = str(post_info.find(\"div\",attrs={\"class\":\"smalltext\"}))\n",
    "            date = date_text_tag[date_text_tag.find(\"/strong>\")+9:date_text_tag.find(\"</div\")-2]\n",
    "            try: \n",
    "                date = parse(date)\n",
    "            except:\n",
    "                date = parse(\"0:00\")\n",
    "            poster_info = main_post.find(\"div\",attrs={\"class\":\"poster\"})\n",
    "            author_tag = str(poster_info.find(\"a\"))\n",
    "            author_text = author_tag.split(\" \")[-1]\n",
    "            author = author_text[author_text.index(\">\")+1:author_text.index(\"<\")]\n",
    "            author_numposts_tag = str(poster_info.find(\"li\",{\"class\":\"postcount\"}))\n",
    "            author_numposts_text = author_numposts_tag.split(\" \")[-1]\n",
    "            author_numposts = author_numposts_text[0:author_numposts_text.index(\"<\")] \n",
    "            author_type_tag = str(poster_info.find(\"li\",{\"class\":\"postgroup\"}))\n",
    "            author_type_text = author_type_tag.split(\" \")[-1]\n",
    "            author_type = author_type_text[author_type_text.index(\">\")+1:author_type_text.index(\"<\")] \n",
    "            author_karma_tag = str(poster_info.find(\"li\",{\"class\":\"karma\"}))\n",
    "            author_karma_text = author_karma_tag.split(\" \")[-1]\n",
    "            author_karma = author_karma_text[0:author_karma_text.index(\"<\")]\n",
    "\n",
    "            #response post(s)\n",
    "            if len(forum_post) > 1:\n",
    "                for j in range(1, len(forum_post)):\n",
    "                    response = forum_post[j]\n",
    "                    responder_info = response.find(\"div\",attrs={\"class\":\"poster\"})\n",
    "                    response_date_text_tag = str(responder_info.find(\"div\",attrs={\"class\":\"smalltext\"}))\n",
    "                    response_date = response_date_text_tag[response_date_text_tag.find(\"/strong>\")+9:response_date_text_tag.find(\"</div\")-2]\n",
    "                    try: \n",
    "                        response_date = parse(response_date)\n",
    "                    except:\n",
    "                        response_date = parse(\"0:00\")\n",
    "                    responder_tag = str(responder_info.find(\"a\"))\n",
    "                    responder_text = responder_tag.split(\" \")[-1]\n",
    "                    responder = responder_text[responder_text.index(\">\")+1:responder_text.index(\"<\")]                \n",
    "                    responder_numposts_tag = str(responder_info.find(\"li\",{\"class\":\"postcount\"}))\n",
    "                    responder_numposts_text = responder_numposts_tag.split(\" \")[-1]\n",
    "                    responder_numposts = responder_numposts_text[0:responder_numposts_text.index(\"<\")] \n",
    "                    \n",
    "                    responder_type_tag = str(responder_info.find(\"li\",{\"class\":\"postgroup\"}))\n",
    "                    responder_type_text = responder_type_tag.split(\" \")[-1]\n",
    "                    responder_type = responder_type_text[responder_type_text.index(\">\")+1:responder_type_text.index(\"<\")] \n",
    "                    responder_karma_tag = str(responder_info.find(\"li\",{\"class\":\"karma\"}))\n",
    "                    responder_karma_text = responder_karma_tag.split(\" \")[-1]\n",
    "                    responder_karma = responder_karma_text[0:responder_karma_text.index(\"<\")]                \n",
    "\n",
    "                    #Creates a numpy array with the scraped values\n",
    "                    new_t = np.array([topic, date, author, author_numposts, author_type, author_karma, response_date,\n",
    "                                   responder, responder_numposts, responder_type, responder_karma])\n",
    "                    #Appends array to data frame\n",
    "                    df_topic = df_topic.append(pd.DataFrame(new_t, index=col_names_topic).transpose())\n",
    "\n",
    "            else:\n",
    "                response_date = \"0:00\"\n",
    "                responder = \"\"\n",
    "                responder_numposts = \"\"\n",
    "                responder_type = \"\"\n",
    "                responder_karma = \"\"\n",
    "\n",
    "                #Creates a numpy array with the scraped values\n",
    "                new_t = np.array([topic, date, author, author_numposts, author_type, author_karma, response_date,\n",
    "                               responder, responder_numposts, responder_type, responder_karma])\n",
    "                #Appends array to data frame\n",
    "                df_topic = df_topic.append(pd.DataFrame(new_t, index=col_names_topic).transpose())\n",
    "\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "    except:\n",
    "        print \"File \" + i + \" has failed\"\n",
    "\n",
    "#Remove duplicates and reindex\n",
    "df_profile = df_profile.drop_duplicates(keep=\"first\")\n",
    "df_profile.index = range(df_profile.shape[0])\n",
    "\n",
    "df_topic = df_topic.drop_duplicates(keep=\"first\")\n",
    "df_topic.index = range(df_topic.shape[0])\n",
    "\n",
    "\n",
    "df_profile.to_csv(\"data_output/df_profile.csv\", encoding=\"utf=8\")\n",
    "df_topic.to_csv(\"data_output/df_topic.csv\",encoding=\"utf-8\")\n",
    "        \n",
    "os.chdir(wdir) #Reset current working directory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
